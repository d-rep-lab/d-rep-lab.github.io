{
  "title": "Ongoing Projects",
  "bg_color": "#f8fafc",
  "items": [
    {
      "title": "Representation Learning for Visual Analysis",
      "description": "Effective data processing and feature extraction are crucial for gaining insights into target phenomena captured in complex datasets. We develop representation learning methods such as dimensionality reduction, tensor decomposition, graph embedding, and neural network–based encoders. Our approaches are designed with visual and multimodal analytics in mind, addressing factors such as computational latency, visual consistency, interpretability, and interactive usability. These representation learning methods provide a fundamental foundation for building effective visualizations and physicalizations.",
      "examples": [
        {
          "title": "N. Okami, K. Miyake, N. Sakamoto, J. Nonaka, and T. Fujiwara. “Visual Analytics Using Tensor Unified Linear Comparative Analysis.” IEEE Transactions on Visualization and Computer Graphics (Special Issue: IEEE VIS 2025), forthcoming.",
          "url": "#publications?search=\"Tensor Unified Linear Comparative Analysis\""
        },
        {
          "title": "T. Fujiwara, X. Wei, J. Zhao, and K.-L. Ma. “Interactive Dimensionality Reduction for Comparative Analysis.” IEEE Transactions on Visualization and Computer Graphics (Special Issue: IEEE VIS 2021), 2022.",
          "url": "#publications?search=\"Interactive Dimensionality Reduction for Comparative Analysis\""
        },
        {
          "title": "T. Fujiwara, Y.-H. Kuo, A. Ynnerman, K.-L. Ma. “Feature Learning for Nonlinear Dimensionality Reduction toward Maximal Extraction of Hidden Patterns.” Proc. PacificVis, 2023.",
          "url": "#publications?search=\"Feature Learning for Nonlinear Dimensionality Reduction\""
        }
      ],
      "images": [
        "./images/projects/ccpca.png",
        "./images/projects/networkcv.png",
        "./images/projects/multidr.png"
      ],
      "tags": [
        "Visualization",
        "Dimensionality Reduction",
        "Machine Learning",
        "Visual Analytics"
      ]
    },
    {
      "title": "3D Representations for Large-Scale, High-dimensional, and Complex Data",
      "description": "A 3D space provides an expressive visual and physical medium for analyzing large-scale, high-dimensional, and complex data. We design 3D visualizations and physicalizations beyond traditional 2D approaches to reveal and present data patterns and structures that cannot be adequately captured in 2D spaces. Our work holistically addresses the challenges of 3D representations, including computational algorithms for extracting 3D patterns, rendering techniques optimized for 3D spaces, and analysis/presentation environments, such as XR, VR, and planetariums.",
      "examples": [
        {
          "title": "W. Duchemin*, T. Fujiwara*, H. W. Herhold, E. Elmquist, D. S. Thaler, W. Harcourt-Smith, E. Broman, A. Bock, B. P. Abbott, J. K. Faherty (*equally contributed). “A Cosmic View of Life on Earth: Hierarchical Visualization of Biological Data Using Astronomical Software.” IEEE Computer Graphics and Applications, 2025",
          "url": "#publications?search=\"Cosmic View of Life on Earth\""
        },
        {
          "title": "S. S. Bae, T. Fujiwara, A. Ynnerman, E. Y.-L. Do, M. L. Rivera, and D. A. Szafir. “A Computational Design Pipeline to Fabricate Sensing Network Physicalizations.” IEEE Transactions on Visualization and Computer Graphics (Special Issue: IEEE VIS 2023), 2025",
          "url": "#publications?search=\"A Computational Design Pipeline to Fabricate Sensing Network Physicalizations\""
        },
        {
          "title": "Y.-J. Huang, T. Fujiwara, Y.-X. Lin, W.-C. Lin, and K.-L. Ma. “A Gesture System for Graph Visualization in Virtual Reality Environments.” Proc. IEEE PacificVis (short paper), 2017",
          "url": "#publications?search=\"Gesture System for Graph Visualization\""
        }
      ],
      "images": [
        "./images/projects/cvol.png",
        "./images/projects/protein_network.png",
        "./images/projects/brain_network.png"
      ],
      "tags": [
        "Physicalization",
        "3D",
        "XR",
        "HCI"
      ]
    },
    {
      "title": "Using Mixed-Reality for STEM Education and Analytical Tasks",
      "description": "We explore how immersive technologies such as AR/VR and mixed reality setups can transform the way scientists and students engage with data. We collaborate with domain scientists, like in material science and optics, to explore the opportunities these emergent technologies afford for data-driven discovery and analysis. We also explore how a mixed-reality setup of bridging both the physical and virtual worlds can improve STEM learning for complex topics such as AI and data science. Through these investigations, we develop tools and guidelines that maximize the potential of these technologies for educational and analytical contexts.",
      "examples": [
        {
          "title": "S. S. Bae, R. Vanukuru, R. Yang, P. Gyory, R. Zhou, E. Y.-L. Do, and D. A. Szafir. “Cultivating Visualization Literacy for Children Through Curiosity and Play”. In: IEEE Transactions on Visualization and Computer Graphics (also proc. IEEE VIS 2022).",
          "url": "#publications?search=\"Cultivating Visualization Literacy for Children Through Curiosity and Play\""
        },
        {
          "title": "K. Takahira, Y. Yu, T. Fujiwara, R. Suzuki, and H. Qu. “InSituTale: Enhancing Augmented Data Storytelling with Physical Objects.” In Proc. ACM UIST",
          "url": "#publications?search=\"InSituTale: Enhancing Augmented Data Storytelling with Physical Objects\""
        },
        {
          "title": "K. Takahira, K.-K. Wong, L. Yang, X. Xu, T. Fujiwara, and H. Qu. “TangibleNet: Synchronous Network Data Storytelling with Tangible User Interfaces in Mixed Reality.” In Proc. ACM CHI, Article No. 233, 18 pages, 2025.",
          "url": "#publications?search=\"TangibleNet\""
        }
      ],
      "images": [
        "./images/pubs/2022_eager.jpg",
        "./images/pubs/2025_tangiblenet.png"
      ],
      "tags": [
        "Physicalization",
        "3D",
        "XR",
        "HCI"
      ]
    },
    {
      "title": "Computationally Fabricating Interactive 3D Printed Objects",
      "description": "Our research in fabrication focuses on revolutionizing how we develop interactive data physicalizations (i.e., physical data representations). These tangible artifacts offer a new modality of interacting with data and an opportunity to bridge the digital and physical worlds. A central challenge in creating interactive physicalizations is the cross-disciplinary expertise needed in visualization, fabrication, and electronics. We combine computational design and machine learning to develop computational pipelines that automate low-level engineering traditionally needed to make interactive objects. The interdisciplinarity of these works lends itself to addressing needs in other fields, such as robotics and computational fabrication.",
      "examples": [
        {
          "title": "S. S. Bae, T. Fujiwara, A. Ynnerman, E. Y.-L. Do, M. Rivera, and D. A. Szafir. “A Computational Design Pipeline to Fabricate Sensing Network Physicalizations”. In: IEEE Transactions on Visualization and Computer Graphics (also proc. IEEE VIS 2023).",
          "url": "#publications?search=\"A Computational Design Pipeline to Fabricate Sensing Network Physicalizations\""
        },
        {
          "title": "S. S. Bae*, T. Fujiwara*, D. A. Szafir, E. Y.-L. Do, and M. L. Rivera. “Computational Design and Single- Wire Sensing of 3D Printed Objects with Integrated Capacitive Touchpoints”. In: Proceedings of the 10th ACM Symposium on Computational Fabrication",
          "url": "#publications?search=\"Computational Design and Single- Wire Sensing of 3D Printed Objects with Integrated Capacitive Touchpoints\""
        },
        {
          "title": "C. Kohlbrenner, C. Esobedo, S. S. Bae, A. Dickhans, and A. Roncone. “GenTact Toolbox: A Computational Design Pipeline to Procedurally Generate Context-Driven 3D Printed Large-Area Tactile Skins”. In: Proceedings of the 2025 IEEE International Conference on Robotics and Automation",
          "url": "#publications?search=\"GenTact Toolbox: A Computational Design Pipeline to Procedurally Generate Context-Driven 3D Printed Large-Area Tactile Skins\""
        }
      ],
      "images": [
        "./images/pubs/2023_sensing_network.png",
        "./images/pubs/2025_freeform_interface.png",
        "./images/pubs/2025_gentact.jpg"
      ],
      "tags": [
        "Physicalization",
        "3D",
        "XR",
        "HCI"
      ]
    },
    {
      "title": "Enhancing Data Representations through Cognitive Science",
      "description": "As we introduce novel data representations, we want to ensure that they are perceptually effective. Perceptual effectiveness designs draw upon psychological insights to ensure design choices (e.g., color) carefully match how humans perceive information efficiently and accurately. While traditional visualizations (such as line charts and scatterplots) have been extensively studied, we lack comparable empirical investigations for emerging forms like immersive visualizations and data physicalizations. We conduct empirical investigations to examine the cognitive and perceptual processes involved in interpreting these novel data representations. These findings not only deepen our understanding of how people make sense of data in new mediums but also guide the design and development of more effective future systems.",
      "examples": [
        {
          "title": "S. S. Bae*, T. Fujiwara*, C. Tseng*, and D. A. Szafir. “Uncovering How Scatterplot Features Skew Visual Class Separation”. In: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems.",
          "url": "#publications?search=\"Uncovering How Scatterplot Features Skew Visual Class Separation\""
        },
        {
          "title": "S. S. Bae, K. Cave, C. Görg, P. Rosen, D. A. Szafir, and C. X. Bearfield. “Bridging Network Science and Vision Science: Mapping Perceptual Mechanisms to Network Visualization Tasks”. In: IEEE Transactions on Visualization and Computer Graphics (2025).",
          "url": "#publications?search=\"Bridging Network Science and Vision Science: Mapping Perceptual Mechanisms to Network Visualization Tasks\""
        }
      ],
      "images": [
        "./images/pubs/2025_vcs_perception.png",
        "./images/pubs/2025_visual_perception.png"
      ],
      "tags": [
        "HCI"
      ]
    }
  ]
}